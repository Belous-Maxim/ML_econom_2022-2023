{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ddec245",
   "metadata": {},
   "source": [
    "# План семинара\n",
    "- Функционалы и метрики\n",
    "- Кросс-валидация\n",
    "- Переобучение и регуляризация\n",
    "- Гиперпараметры и их оптимизация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb3db5c",
   "metadata": {},
   "source": [
    "# Функционалы и метрики\n",
    "\n",
    "Quick recap\n",
    "\n",
    "Функционал (или функция потерь == loss function)  - это функция, позволяющая обучить модель (то есть то, что мы стараемся оптимизировать, подбирая параметры модели - в случае линейной регрессии параметры - это веса)\n",
    "\n",
    "Метрика - это оценка качества модели, которую можно использовать к любым моделям (позволяет ответить на вопрос, насколько точно модель может предсказывать целевую переменную)\n",
    "\n",
    "Пример: Чтобы обучить линейную регрессию мы можем минизировать функционал MSE\n",
    "\n",
    "Если мы имеем n наблюдений и k признаков\n",
    "\n",
    "$\\Sigma_{i=0}^{n}(\\hat y_{i} - y_{i})^{2} \\rightarrow min_{w}$\n",
    "\n",
    "где $\\hat y_{i} = \\Sigma_{i=0}^{k}w_{k}X_{ik}$\n",
    "\n",
    "А как метрику можем использовать RMSE\n",
    "\n",
    "$RMSE = \\sqrt{\\Sigma_{i=0}^{n}(\\hat y_{i} - y_{i})^{2}}$\n",
    "\n",
    "Фундаментальное различие функционала и метрик в том, что метрика должна отражать нашу бизнес-задачу или научный вопрос, а функционал должен быть подобран так, чтобы он лучше лучше всего помогал достичь цель (позволял достичь наилучшных показателей метрики или метрик)\n",
    "\n",
    "Аналогия из обучения в вышке: Чтобы сдать матан, мы можем учить производные различных функций, то есть тогда наш функционал - это количество производных, которые мы знаем. А метрикой того, что мы сдали матан будет являться оценка, полученная в конце курса.\n",
    "\n",
    "Оценка в курсе - это понятная метрика, которую нам дал мир. А является ли зубрежка производных лучшим функционалом для достижения поставленной цели решать уже вам, как исследователям\n",
    "\n",
    "И еще, хотя функционал и метрики - это разные по смыслу и использованию инстурменты, они могут быть считаться одинаково (то есть к примеру обучать линейную регрессию можно обучать с помощью функционала MSE, и проверять качество тоже можно с помощью MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3058f120",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T09:32:57.719450Z",
     "start_time": "2021-09-19T09:32:57.716564Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.datasets import load_diabetes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d71f211f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T14:18:18.330885Z",
     "start_time": "2021-09-19T14:18:18.328202Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15bbd22d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T09:34:43.297161Z",
     "start_time": "2021-09-19T09:34:43.281851Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = load_diabetes(return_X_y=True,as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e67c9f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T09:35:41.927759Z",
     "start_time": "2021-09-19T09:35:41.913315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018118</td>\n",
       "      <td>0.044485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017282</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046879</td>\n",
       "      <td>0.015491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044528</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.073030</td>\n",
       "      <td>-0.081414</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.004220</td>\n",
       "      <td>0.003064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017282 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "441 -0.045472 -0.044642 -0.073030 -0.081414  0.083740  0.027809  0.173816   \n",
       "\n",
       "           s4        s5        s6  \n",
       "0   -0.002592  0.019908 -0.017646  \n",
       "1   -0.039493 -0.068330 -0.092204  \n",
       "2   -0.002592  0.002864 -0.025930  \n",
       "3    0.034309  0.022692 -0.009362  \n",
       "4   -0.002592 -0.031991 -0.046641  \n",
       "..        ...       ...       ...  \n",
       "437 -0.002592  0.031193  0.007207  \n",
       "438  0.034309 -0.018118  0.044485  \n",
       "439 -0.011080 -0.046879  0.015491  \n",
       "440  0.026560  0.044528 -0.025930  \n",
       "441 -0.039493 -0.004220  0.003064  \n",
       "\n",
       "[442 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38c2e3f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T09:34:58.661561Z",
     "start_time": "2021-09-19T09:34:58.656077Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      151.0\n",
       "1       75.0\n",
       "2      141.0\n",
       "3      206.0\n",
       "4      135.0\n",
       "       ...  \n",
       "437    178.0\n",
       "438    104.0\n",
       "439    132.0\n",
       "440    220.0\n",
       "441     57.0\n",
       "Name: target, Length: 442, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "489524d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T09:40:24.845858Z",
     "start_time": "2021-09-19T09:40:24.842070Z"
    }
   },
   "outputs": [],
   "source": [
    "# Разобьем данные на обучающую и тестовую выборки\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd45ddb",
   "metadata": {},
   "source": [
    "Как было рассказано на лекции, линейную регрессию можно обучать с помощью разного функционала (не только MSE, который мы разбирали на прошлом семинаре) и оценивать с помощью разных метрик - закодим это "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4be7da5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T10:12:29.716071Z",
     "start_time": "2021-09-19T10:12:29.484571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE loss: \n",
      "mae=44.77491800936348\n",
      "mse=2974.675736024679\n",
      "R2=0.4159242158014511\n",
      "\n",
      "MAE loss: \n",
      "mae=60.24904452631575\n",
      "mse=5275.558838499551\n",
      "R2=-0.035852791739935386\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "lr_mse = SGDRegressor(loss='squared_loss', max_iter=50000)\n",
    "lr_mae = SGDRegressor(loss='epsilon_insensitive', epsilon=0, max_iter=50000)\n",
    "\n",
    "lr_mse.fit(X_train, y_train)\n",
    "lr_mae.fit(X_train, y_train)\n",
    "\n",
    "y_pred_mse = lr_mse.predict(X_test)\n",
    "y_pred_mae = lr_mae.predict(X_test)\n",
    "\n",
    "print(f'''MSE loss: \n",
    "mae={mean_absolute_error(y_test, y_pred_mse)}\n",
    "mse={mean_squared_error(y_test, y_pred_mse)}\n",
    "R2={r2_score(y_test, y_pred_mse)}\n",
    "''')\n",
    "\n",
    "print(f'''MAE loss: \n",
    "mae={mean_absolute_error(y_test, y_pred_mae)}\n",
    "mse={mean_squared_error(y_test, y_pred_mae)}\n",
    "R2={r2_score(y_test, y_pred_mae)}\n",
    "''')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dd894b",
   "metadata": {},
   "source": [
    "Как мы говорили раньше, метрика должна отражать реальную цель из мира, поэтому нередко возникает потребность в написании своих собственных метрик, которые лучше описывают вашу конретную реальность. В задачах, связанных с медициной (как у нас сейчас), довольно высокая цена ошибки (у человека есть диабет, а мы его не нашли). Поэтому для того, чтобы ответить на вопрос, можно ли модель использовать в жизни, имеет смысл использовать метрику максимальной ошибки модели\n",
    "\n",
    "$max error = max(|\\hat y_{i} - y_{i}|)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e009345",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T11:07:38.199530Z",
     "start_time": "2021-09-19T11:07:38.192248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss: 141.75793790442455\n",
      "MAE Loss: 215.26266316059622\n"
     ]
    }
   ],
   "source": [
    "def max_error(y_true, y_pred):\n",
    "    max_erorr = np.abs(y_true - y_pred).max()\n",
    "    return max_erorr\n",
    "\n",
    "# Оценим максимальную ошибку в обоих случаях\n",
    "\n",
    "print(f'MSE Loss: {max_error(y_test, y_pred_mse)}')\n",
    "print(f'MAE Loss: {max_error(y_test, y_pred_mae)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7861d8de",
   "metadata": {},
   "source": [
    "BTW, в sklearn есть большое количество уже реализованных метрик - можете посмотреть их список и варианты применения здесь\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce6ef8f",
   "metadata": {},
   "source": [
    "#  Кросс-валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c2931b",
   "metadata": {},
   "source": [
    "Когда выбран функционал и метрика, можно задаться вопросом: а насколько я могу доверять полученным результатам (значениям метрики), не являются ли они случайности или совпадением ? Кросс-валидация - это инструмент для ответа на этот вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9521ed63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T10:43:33.682547Z",
     "start_time": "2021-09-19T10:43:33.679968Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37de7e3",
   "metadata": {},
   "source": [
    "здесь можно посмотреть какие параметры требуются для этой функции\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=None, shuffle=True)\n",
    "kf.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95258cdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T11:29:33.961814Z",
     "start_time": "2021-09-19T11:29:33.028939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mse errors are [-2679.37359605 -3636.66493469 -2511.27382572 -3190.50769785\n",
      " -3022.81220384]\n",
      "mean test mse = -3008.1264516298556\n"
     ]
    }
   ],
   "source": [
    "# проверим на кросс-валидации значения ошибок MSE, MAE, R2 \n",
    "# для линейной регрессии, обученной с помощью функционала MSE\n",
    "\n",
    "num_splits=5\n",
    "\n",
    "cv_res = cross_validate(lr_mse,\n",
    "                     X,\n",
    "                     y,\n",
    "                     scoring='neg_mean_squared_error', # метрика, которую нужно оценить\n",
    "                     cv=kf # количество разбиений или класс-сплиттер\n",
    "                    )\n",
    "\n",
    "print(f\"test mse errors are {cv_res['test_score']}\")\n",
    "print(f\"mean test mse = {cv_res['test_score'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abeb9c81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T11:29:34.789243Z",
     "start_time": "2021-09-19T11:29:33.963938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mse errors are [-2957.68437903 -3037.73122878 -3163.58758502 -2876.06566229\n",
      " -3056.40614826] \n",
      "and  mean mse = -3018.2950006761944\n",
      "\n",
      "test mae errors are [-44.8088895  -44.96678863 -48.06278843 -42.79081165 -44.29174918] \n",
      "and  mean mae = -44.98420547703752\n",
      "\n",
      "test R2 are [0.39307938 0.52119739 0.49452028 0.45178828 0.52765523] \n",
      "and  mean R2 = 0.4776481111184281\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Проведем кросс-валидацию сразу для нескольких метрик\n",
    "\n",
    "cv_res2 = cross_validate(lr_mse,\n",
    "                     X,\n",
    "                     y,\n",
    "                     scoring=['neg_mean_squared_error', 'neg_mean_absolute_error', 'r2'],\n",
    "                     cv=num_splits\n",
    "                    )\n",
    "print(f\"\"\"test mse errors are {cv_res2['test_neg_mean_squared_error']} \n",
    "and  mean mse = {cv_res2['test_neg_mean_squared_error'].mean()}\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\"\"test mae errors are {cv_res2['test_neg_mean_absolute_error']} \n",
    "and  mean mae = {cv_res2['test_neg_mean_absolute_error'].mean()}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "print(f\"\"\"test R2 are {cv_res2['test_r2']} \n",
    "and  mean R2 = {cv_res2['test_r2'].mean()}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb809c98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T11:29:35.686895Z",
     "start_time": "2021-09-19T11:29:34.791046Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-136.72273433, -160.76048158, -120.69258409, -128.55167229,\n",
       "       -134.83470475])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# для тех, кто хочет хочет дополнительно подумать\n",
    "\n",
    "# кросс-валидацию можно проводить на основе своей кастомной метрики, но для этого\n",
    "# из нее нужно сделать объект scorer\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "max_error_scorer = make_scorer(max_error, greater_is_better=False)\n",
    "\n",
    "cv_res3 = cross_validate(lr_mse,\n",
    "                     X,\n",
    "                     y,\n",
    "                     scoring=max_error_scorer,\n",
    "                     cv=num_splits\n",
    "                    )\n",
    "cv_res3['test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36823ea1",
   "metadata": {},
   "source": [
    "# Немного feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ffde24",
   "metadata": {},
   "source": [
    "Один из самых главных источников улучшения качества прогноза модели - это информативный набор признаков. Поэтому в попытке улучшить качество нашей модели обогатим наше признаковое пространство попарными произведениями признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c1b8654",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T14:57:18.290913Z",
     "start_time": "2021-09-19T14:57:18.220547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>...</th>\n",
       "      <th>s6_x_age</th>\n",
       "      <th>s6_x_sex</th>\n",
       "      <th>s6_x_bmi</th>\n",
       "      <th>s6_x_bp</th>\n",
       "      <th>s6_x_s1</th>\n",
       "      <th>s6_x_s2</th>\n",
       "      <th>s6_x_s3</th>\n",
       "      <th>s6_x_s4</th>\n",
       "      <th>s6_x_s5</th>\n",
       "      <th>s6_x_s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000672</td>\n",
       "      <td>-0.000894</td>\n",
       "      <td>-0.001089</td>\n",
       "      <td>-0.000386</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-0.000351</td>\n",
       "      <td>0.000311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.004116</td>\n",
       "      <td>0.004746</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>-0.006861</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.008502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002212</td>\n",
       "      <td>-0.001314</td>\n",
       "      <td>-0.001153</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>-0.000074</td>\n",
       "      <td>0.000672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>-0.000321</td>\n",
       "      <td>-0.000212</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000251</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>-0.001020</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>-0.000727</td>\n",
       "      <td>-0.000380</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>0.002175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-0.000207</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018118</td>\n",
       "      <td>0.044485</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000245</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>-0.000708</td>\n",
       "      <td>-0.003009</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0.003522</td>\n",
       "      <td>-0.001276</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>-0.000806</td>\n",
       "      <td>0.001979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017282</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046879</td>\n",
       "      <td>0.015491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>-0.000246</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>-0.000578</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>-0.000387</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>-0.000726</td>\n",
       "      <td>0.000240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044528</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>-0.001013</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-0.000423</td>\n",
       "      <td>-0.000396</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>-0.000689</td>\n",
       "      <td>-0.001155</td>\n",
       "      <td>0.000672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.073030</td>\n",
       "      <td>-0.081414</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.004220</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000139</td>\n",
       "      <td>-0.000137</td>\n",
       "      <td>-0.000224</td>\n",
       "      <td>-0.000249</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>-0.000121</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017282 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "441 -0.045472 -0.044642 -0.073030 -0.081414  0.083740  0.027809  0.173816   \n",
       "\n",
       "           s4        s5        s6  ...  s6_x_age  s6_x_sex  s6_x_bmi  \\\n",
       "0   -0.002592  0.019908 -0.017646  ... -0.000672 -0.000894 -0.001089   \n",
       "1   -0.039493 -0.068330 -0.092204  ...  0.000174  0.004116  0.004746   \n",
       "2   -0.002592  0.002864 -0.025930  ... -0.002212 -0.001314 -0.001153   \n",
       "3    0.034309  0.022692 -0.009362  ...  0.000834  0.000418  0.000109   \n",
       "4   -0.002592 -0.031991 -0.046641  ... -0.000251  0.002082  0.001697   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "437 -0.002592  0.031193  0.007207  ...  0.000301  0.000365  0.000142   \n",
       "438  0.034309 -0.018118  0.044485  ... -0.000245  0.002255 -0.000708   \n",
       "439 -0.011080 -0.046879  0.015491  ...  0.000646  0.000785 -0.000246   \n",
       "440  0.026560  0.044528 -0.025930  ...  0.001179  0.001158 -0.001013   \n",
       "441 -0.039493 -0.004220  0.003064  ... -0.000139 -0.000137 -0.000224   \n",
       "\n",
       "      s6_x_bp   s6_x_s1   s6_x_s2   s6_x_s3   s6_x_s4   s6_x_s5   s6_x_s6  \n",
       "0   -0.000386  0.000780  0.000614  0.000766  0.000046 -0.000351  0.000311  \n",
       "1    0.002428  0.000779  0.001767 -0.006861  0.003641  0.006300  0.008502  \n",
       "2    0.000147  0.001182  0.000887  0.000839  0.000067 -0.000074  0.000672  \n",
       "3    0.000343 -0.000114 -0.000234  0.000337 -0.000321 -0.000212  0.000088  \n",
       "4   -0.001020 -0.000184 -0.000727 -0.000380  0.000121  0.001492  0.002175  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "437  0.000431 -0.000041 -0.000018 -0.000207 -0.000019  0.000225  0.000052  \n",
       "438 -0.003009  0.002195  0.003522 -0.001276  0.001526 -0.000806  0.001979  \n",
       "439  0.000268 -0.000578 -0.000214 -0.000387 -0.000172 -0.000726  0.000240  \n",
       "440 -0.000032 -0.000423 -0.000396  0.000744 -0.000689 -0.001155  0.000672  \n",
       "441 -0.000249  0.000257  0.000085  0.000533 -0.000121 -0.000013  0.000009  \n",
       "\n",
       "[442 rows x 110 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "cols = copy.deepcopy(X.columns)\n",
    "print(cols)\n",
    "\n",
    "for col1 in cols:\n",
    "    for col2 in cols:\n",
    "        col_name = col1 + '_x_' + col2\n",
    "        if col_name not in X.columns:\n",
    "            X[col_name] = X[col1]*X[col2]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7dc5ad",
   "metadata": {},
   "source": [
    "# Переобучение и регуляризация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95b3f10",
   "metadata": {},
   "source": [
    "Переобучение - ситуация, когда модель хорошо выучила обучающую выборку, но при этом показывает гораздо более низкое качество точности на тестовых данных. Это можно интерпретровать как модель стала слишком специфичной и потеряла обобщающую способность\n",
    "\n",
    "В случае линеной регрессии, одним из симптомов переобучения являются высокие значения весов. С этим борются регуляризацией.\n",
    "\n",
    "Регуляризация Lasso или L1-регуляризация:\n",
    "\n",
    "$Q_{lasso}(w) = Q(w) + \\alpha \\Sigma_{j=0}^{k}|w_{k}|$\n",
    "\n",
    "Регуляризация Ridge или L2-регуляризация:\n",
    "\n",
    "$Q_{ridge}(w) = Q(w) + \\alpha \\Sigma_{j=0}^{k}w_{k}^{2}$\n",
    "\n",
    "\n",
    "Как было рассказано в лекции, несмотря на то, что оба вида регуляризации ведут к занижению значений весов, отличие регуляризации Lasso заключается в том, что она может привести часть весов к 0 (что эквивалетно безинформативности  соответствующего признака), в случае Ridge регрессии веса могут быть сколько угодно близки к 0, но никогда не равны.\n",
    "\n",
    "Объяснение в лекции :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74371b19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T14:58:15.386513Z",
     "start_time": "2021-09-19T14:58:15.380982Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e075e43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T14:58:16.692634Z",
     "start_time": "2021-09-19T14:58:16.619052Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=1e-08\n",
      "Train MSE: 2345.9534339049565\n",
      "Test MSE: 3521.577254360907\n",
      "[ 9.25941410e+01  1.71306204e+02  3.24650712e+02  4.32251283e+02\n",
      " -1.83536164e+02 -7.47258955e+01 -1.16783083e+02  1.71498640e+02\n",
      "  6.86117767e+02  1.55369978e+01  1.06682008e+03  3.66205819e+03\n",
      "  2.81048428e+02 -1.55851461e+02  4.59285888e+03 -7.21278906e+03\n",
      " -1.46831713e+03  1.12069900e+01  1.35525316e+02  2.44423200e+03\n",
      " -4.84443045e+02 -6.04346096e+04  2.15877524e+03  1.01106426e+03\n",
      "  7.17086989e+03 -7.67839549e+03 -2.77035689e+03 -2.26628089e+03\n",
      " -3.04565999e+03  7.44576293e+02 -1.05188359e+03  8.77647062e+02\n",
      "  3.20548709e+03  4.13322199e+02 -1.04055804e+04  7.38505305e+03\n",
      "  7.27285536e+03 -7.96196035e+02  1.13001771e+03  1.45591569e+03\n",
      " -9.31029582e+02  1.62334753e+01  9.73547286e+02  4.66175788e+02\n",
      "  2.13581557e+03 -1.19359492e+03  6.01997506e+02 -2.36416106e+03\n",
      " -2.03224136e+02 -1.34394594e+03  6.11701279e+03  9.43340800e+03\n",
      " -1.09264516e+04  2.40761530e+03 -1.93572230e+03 -7.85690663e+02\n",
      "  2.67667300e+03  5.52634699e+03 -1.20089989e+04  4.84515521e+03\n",
      " -4.87480061e+03 -4.51503709e+03  1.13099072e+04 -1.05450001e+03\n",
      " -2.49505021e+03  5.69559937e+03  7.02445247e+02 -5.42134658e+03\n",
      "  1.05556575e+04 -4.28254629e+03 -2.32071879e+03 -4.48033644e+03\n",
      "  2.93857678e+03 -1.68177048e+03  4.66036460e+03 -5.96276965e+03\n",
      " -2.53941816e+03 -1.33054596e+03  5.56724436e+03  1.17778579e+03\n",
      " -1.15257238e+03 -2.78307472e+03  8.03887003e+02  7.24095294e+02\n",
      " -3.30423416e+02 -2.78792897e+03 -4.86876257e+03 -4.83366715e+02\n",
      " -4.98833753e+02  2.74294775e+03  5.91116123e+00 -3.14941635e+03\n",
      "  3.56220876e+03  8.51698232e+02 -1.00285119e+04  1.02912335e+04\n",
      "  3.73258161e+03  1.07354285e+03  6.64223313e+03 -9.41675077e+02\n",
      " -7.52472255e+02 -6.41457812e+01 -6.23419900e+02 -7.48021298e+02\n",
      " -1.66170729e+03  6.13355930e+02  2.53724652e+03  1.76410536e+03\n",
      "  1.63460386e+03  7.27947287e+02] \n",
      "\n",
      "alpha=0.25\n",
      "Train MSE: 2990.4645152216717\n",
      "Test MSE: 3523.471915843845\n",
      "[   0.           -0.          407.37827571  300.64052852   -0.\n",
      "   -0.         -116.22498035    0.          420.05712024    0.\n",
      "    0.            0.            0.            0.           -0.\n",
      "   -0.           -0.            0.            0.            0.\n",
      "    0.           -0.            0.            0.            0.\n",
      "   -0.            0.           -0.            0.            0.\n",
      "    0.            0.            0.            0.            0.\n",
      "    0.           -0.            0.            0.            0.\n",
      "    0.            0.            0.            0.            0.\n",
      "    0.            0.            0.            0.            0.\n",
      "   -0.            0.            0.            0.           -0.\n",
      "   -0.           -0.           -0.            0.            0.\n",
      "   -0.           -0.            0.            0.           -0.\n",
      "   -0.           -0.           -0.           -0.            0.\n",
      "   -0.            0.           -0.            0.           -0.\n",
      "   -0.           -0.            0.            0.            0.\n",
      "    0.           -0.            0.            0.           -0.\n",
      "   -0.            0.           -0.           -0.            0.\n",
      "    0.            0.            0.            0.            0.\n",
      "   -0.            0.           -0.           -0.            0.\n",
      "    0.            0.            0.            0.            0.\n",
      "    0.            0.            0.            0.            0.        ] \n",
      "\n",
      "alpha=0.5\n",
      "Train MSE: 3156.512217087877\n",
      "Test MSE: 3795.2216040953826\n",
      "[  0.          -0.         361.04104239 236.26643984  -0.\n",
      "  -0.         -48.59489579   0.         376.99888841   0.\n",
      "   0.           0.           0.           0.          -0.\n",
      "  -0.          -0.           0.           0.           0.\n",
      "   0.          -0.           0.           0.           0.\n",
      "  -0.           0.          -0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "  -0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "  -0.           0.           0.           0.          -0.\n",
      "  -0.          -0.          -0.           0.           0.\n",
      "  -0.          -0.          -0.           0.          -0.\n",
      "  -0.           0.          -0.          -0.           0.\n",
      "  -0.           0.           0.           0.          -0.\n",
      "   0.          -0.           0.           0.           0.\n",
      "   0.          -0.           0.           0.          -0.\n",
      "  -0.           0.           0.          -0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "  -0.           0.          -0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.        ] \n",
      "\n",
      "alpha=0.75\n",
      "Train MSE: 3421.0614315593266\n",
      "Test MSE: 4177.728012116487\n",
      "[  0.           0.         310.31286025 172.35723104   0.\n",
      "   0.          -0.           0.         327.36451867   0.\n",
      "   0.           0.           0.           0.          -0.\n",
      "  -0.          -0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "  -0.           0.          -0.           0.           0.\n",
      "   0.           0.           0.           0.          -0.\n",
      "  -0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "  -0.           0.          -0.           0.           0.\n",
      "  -0.           0.          -0.           0.          -0.\n",
      "  -0.          -0.           0.           0.           0.\n",
      "  -0.          -0.          -0.          -0.          -0.\n",
      "  -0.           0.          -0.          -0.           0.\n",
      "  -0.           0.           0.           0.          -0.\n",
      "   0.          -0.           0.           0.           0.\n",
      "   0.          -0.           0.          -0.           0.\n",
      "  -0.           0.           0.          -0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "  -0.           0.          -0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.        ] \n",
      "\n",
      "alpha=1.0\n",
      "Train MSE: 3755.434787849969\n",
      "Test MSE: 4642.260458783117\n",
      "[  0.           0.         248.38775881 109.6431891    0.\n",
      "   0.          -0.           0.         260.93326626   0.\n",
      "   0.           0.          -0.           0.          -0.\n",
      "  -0.          -0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "  -0.           0.          -0.           0.           0.\n",
      "  -0.           0.           0.           0.          -0.\n",
      "  -0.           0.          -0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "  -0.           0.          -0.           0.           0.\n",
      "  -0.           0.          -0.           0.          -0.\n",
      "  -0.          -0.           0.           0.           0.\n",
      "  -0.          -0.          -0.          -0.          -0.\n",
      "  -0.           0.          -0.          -0.           0.\n",
      "  -0.           0.           0.           0.          -0.\n",
      "   0.          -0.           0.           0.           0.\n",
      "   0.          -0.          -0.          -0.           0.\n",
      "  -0.           0.           0.          -0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "  -0.           0.          -0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.        ] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# альфа - это гиперпараметр, посмотрим как зависят значения весов от него\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "for a in np.arange(0, 1.1, 0.25):\n",
    "    if a == 0:\n",
    "        a += 0.00000001\n",
    "    lasso = Lasso(alpha=a)\n",
    "    lasso.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_tr = lasso.predict(X_train)\n",
    "    y_pred2 = lasso.predict(X_test)\n",
    "\n",
    "    print('alpha={}'.format(a))\n",
    "    print('Train MSE:', mean_squared_error(y_train, y_pred_tr))\n",
    "    print('Test MSE:', mean_squared_error(y_test, y_pred2))\n",
    "    print(lasso.coef_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fe3f627",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T14:58:43.312225Z",
     "start_time": "2021-09-19T14:58:43.244582Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=1e-08\n",
      "Train MSE: 2339.800508490564\n",
      "Test MSE: 3436.1425749220825\n",
      "[ 9.40425575e+01 -1.96009903e+02  3.42454756e+02  4.26300638e+02\n",
      " -2.42594983e+03  1.91764321e+03  7.15508226e+02  1.37375723e+02\n",
      "  1.44532038e+03  7.28617255e+00  1.10042932e+03  1.45342968e+03\n",
      " -3.75078556e+02 -5.51300806e+02  5.10859712e+03 -5.79122555e+03\n",
      " -1.85010154e+03 -4.85103301e+02  1.74765392e+02  7.79351701e+02\n",
      "  1.45342968e+03 -1.18360264e+00  1.44264949e+03  5.21217636e+02\n",
      "  9.13351422e+03 -6.72960626e+03 -4.07227694e+03 -2.90606207e+03\n",
      " -3.05183008e+03  3.81135444e+02 -3.75078555e+02  1.44264949e+03\n",
      "  3.02356264e+03  7.36840611e+02 -7.41761450e+03  6.57455797e+03\n",
      "  3.78563073e+03 -2.57083160e+02  1.63971707e+03  4.61057104e+02\n",
      " -5.51300806e+02  5.21217636e+02  7.36840611e+02  4.16104799e+02\n",
      "  1.34650351e+03 -2.84261160e+02 -1.58483781e+02 -7.71682804e+02\n",
      "  5.00980888e+02 -1.04826587e+03  5.10859712e+03  9.13351422e+03\n",
      " -7.41761450e+03  1.34650351e+03  5.46117924e+04 -4.63384903e+04\n",
      " -1.77951381e+04 -6.36437733e+02 -3.05213482e+04 -7.83416315e+02\n",
      " -5.79122555e+03 -6.72960626e+03  6.57455797e+03 -2.84261159e+02\n",
      " -4.63384903e+04  4.04401134e+04  1.45108224e+04 -1.00906651e+03\n",
      "  2.55311344e+04  2.58866056e+02 -1.85010154e+03 -4.07227694e+03\n",
      "  3.78563073e+03 -1.58483782e+02 -1.77951381e+04  1.45108224e+04\n",
      "  5.33334872e+03 -2.20225080e+03  1.22508800e+04  2.73695044e+03\n",
      " -4.85103300e+02 -2.90606207e+03 -2.57083161e+02 -7.71682804e+02\n",
      " -6.36437734e+02 -1.00906651e+03 -2.20225080e+03 -6.39599304e+02\n",
      "  1.81172768e+03  2.24215518e+03  1.74765391e+02 -3.05183008e+03\n",
      "  1.63971707e+03  5.00980888e+02 -3.05213482e+04  2.55311344e+04\n",
      "  1.22508800e+04  1.81172768e+03  1.63326916e+04  1.08952202e+03\n",
      "  7.79351702e+02  3.81135444e+02  4.61057103e+02 -1.04826587e+03\n",
      " -7.83416312e+02  2.58866057e+02  2.73695044e+03  2.24215519e+03\n",
      "  1.08952202e+03  7.04959874e+02] \n",
      "\n",
      "alpha=0.25\n",
      "Train MSE: 2892.798415192853\n",
      "Test MSE: 3351.862295807161\n",
      "[  28.6699386  -113.06046729  363.44868788  325.15656061  -36.63625379\n",
      "  -89.20858149 -170.34485952  104.46755535  370.45468318   55.81782459\n",
      "   17.75790269   21.99458526    3.67179673   15.24924507   -0.61282838\n",
      "   -6.3527489    -2.5851444     4.74539358   15.62190875   16.84036001\n",
      "   21.99458526   -0.68271362   16.32349792   15.59703383    6.58709295\n",
      "   -0.83293126    6.80754678   -2.96709588    8.30749967   13.09376398\n",
      "    3.67179673   16.32349792   32.40738428   23.82895716    1.66203355\n",
      "    1.8581512    -2.07028096    3.82966357    4.64079702   19.85717418\n",
      "   15.24924507   15.59703383   23.82895716   21.33475012    7.70436796\n",
      "    2.06963549    5.18856604    1.02146732   13.32557968   15.38695972\n",
      "   -0.61282838    6.58709295    1.66203355    7.70436796   -3.62952573\n",
      "   -6.36870991    2.11942458   -5.65595993    1.7917561    11.2652739\n",
      "   -6.3527489    -0.83293126    1.8581512     2.06963549   -6.36870991\n",
      "   -9.0397918    -1.65339656   -4.49103931    1.6799411     6.78448112\n",
      "   -2.5851444     6.80754678   -2.07028096    5.18856604    2.11942458\n",
      "   -1.65339656   -2.97817752    2.23482309   11.25703861    2.64954901\n",
      "    4.74539358   -2.96709588    3.82966357    1.02146732   -5.65595993\n",
      "   -4.49103931    2.23482309   -4.28806588   -6.53478367    6.32673737\n",
      "   15.62190875    8.30749967    4.64079702   13.32557968    1.7917561\n",
      "    1.6799411    11.25703861   -6.53478367   -5.19919694   11.8290576\n",
      "   16.84036001   13.09376398   19.85717418   15.38695972   11.2652739\n",
      "    6.78448112    2.64954901    6.32673737   11.8290576    23.14722035] \n",
      "\n",
      "alpha=0.5\n",
      "Train MSE: 3043.9899458423056\n",
      "Test MSE: 3567.715414237277\n",
      "[ 3.35327451e+01 -7.35545712e+01  3.06197450e+02  2.72437178e+02\n",
      " -1.54809400e+01 -6.18435031e+01 -1.56283288e+02  1.04243320e+02\n",
      "  3.01059448e+02  7.34844675e+01  8.41846011e+00  1.06543201e+01\n",
      "  1.36338196e+00  8.26269280e+00 -1.12040435e+00 -4.56051071e+00\n",
      " -1.40498157e+00  1.90744739e+00  8.30063058e+00  8.41922318e+00\n",
      "  1.06543201e+01 -4.44157972e-01  8.25718102e+00  7.82754601e+00\n",
      "  3.08602383e+00 -1.09593710e+00  4.00373400e+00 -1.94167289e+00\n",
      "  4.33863520e+00  6.66895240e+00  1.36338196e+00  8.25718102e+00\n",
      "  1.90107290e+01  1.33212133e+01 -1.30380273e-01 -4.83986700e-01\n",
      " -9.76710149e-01  1.52399694e+00  2.58480174e+00  1.12101167e+01\n",
      "  8.26269280e+00  7.82754601e+00  1.33212133e+01  1.35035080e+01\n",
      "  3.69102192e+00  1.04081806e-01  2.74995533e+00  2.72175131e-01\n",
      "  7.59159466e+00  8.86835116e+00 -1.12040435e+00  3.08602383e+00\n",
      " -1.30380273e-01  3.69102192e+00 -2.14035338e+00 -4.05837392e+00\n",
      "  9.74994382e-01 -2.67426933e+00  9.96141413e-01  5.77280211e+00\n",
      " -4.56051071e+00 -1.09593710e+00 -4.83986700e-01  1.04081806e-01\n",
      " -4.05837392e+00 -5.46370096e+00  5.96408344e-01 -3.48905724e+00\n",
      " -8.28628569e-01  2.74717179e+00 -1.40498157e+00  4.00373400e+00\n",
      " -9.76710149e-01  2.74995533e+00  9.74994382e-01  5.96408344e-01\n",
      " -3.81667805e+00  2.18985621e+00  5.44686267e+00  1.09259812e+00\n",
      "  1.90744739e+00 -1.94167289e+00  1.52399694e+00  2.72175131e-01\n",
      " -2.67426933e+00 -3.48905724e+00  2.18985621e+00 -2.16878980e+00\n",
      " -2.55533864e+00  3.60711356e+00  8.30063058e+00  4.33863520e+00\n",
      "  2.58480174e+00  7.59159466e+00  9.96141413e-01 -8.28628569e-01\n",
      "  5.44686267e+00 -2.55533864e+00 -1.01847048e+00  6.92172634e+00\n",
      "  8.41922318e+00  6.66895240e+00  1.12101167e+01  8.86835116e+00\n",
      "  5.77280211e+00  2.74717179e+00  1.09259812e+00  3.60711356e+00\n",
      "  6.92172634e+00  1.25210992e+01] \n",
      "\n",
      "alpha=0.75\n",
      "Train MSE: 3184.6245830319863\n",
      "Test MSE: 3775.9010875149434\n",
      "[ 3.57286650e+01 -4.99177895e+01  2.66003168e+02  2.36434307e+02\n",
      " -4.06550771e+00 -4.24031526e+01 -1.43197332e+02  1.01502281e+02\n",
      "  2.57920275e+02  7.90294958e+01  5.26101099e+00  6.88128758e+00\n",
      "  5.49138652e-01  5.69567420e+00 -1.27847798e+00 -3.79317089e+00\n",
      " -1.00985603e+00  9.78538931e-01  5.62274278e+00  5.49377185e+00\n",
      "  6.88128758e+00 -3.01427685e-01  5.46198720e+00  5.18327494e+00\n",
      "  1.92227631e+00 -1.06937301e+00  2.96473672e+00 -1.52047035e+00\n",
      "  2.91239520e+00  4.43201252e+00  5.49138652e-01  5.46198720e+00\n",
      "  1.39205198e+01  9.43732823e+00 -5.72553406e-01 -1.03965196e+00\n",
      " -5.63397726e-01  7.90288980e-01  1.80415166e+00  7.98151293e+00\n",
      "  5.69567420e+00  5.18327494e+00  9.43732823e+00  1.02766189e+01\n",
      "  2.30135726e+00 -4.41805193e-01  1.93529042e+00  4.86369891e-03\n",
      "  5.41336720e+00  6.35555850e+00 -1.27847798e+00  1.92227631e+00\n",
      " -5.72553406e-01  2.30135726e+00 -1.52463057e+00 -3.03244466e+00\n",
      "  5.63081479e-01 -1.62546714e+00  7.08501597e-01  3.88777358e+00\n",
      " -3.79317089e+00 -1.06937301e+00 -1.03965196e+00 -4.41805193e-01\n",
      " -3.03244466e+00 -3.96412063e+00  1.04378755e+00 -2.79825108e+00\n",
      " -1.36079872e+00  1.49430553e+00 -1.00985603e+00  2.96473672e+00\n",
      " -5.63397726e-01  1.93529042e+00  5.63081479e-01  1.04378755e+00\n",
      " -3.75538955e+00  1.93421245e+00  3.58278605e+00  6.73196192e-01\n",
      "  9.78538931e-01 -1.52047035e+00  7.90288980e-01  4.86369891e-03\n",
      " -1.62546714e+00 -2.79825108e+00  1.93421245e+00 -1.29539441e+00\n",
      " -1.37130372e+00  2.58618587e+00  5.62274278e+00  2.91239520e+00\n",
      "  1.80415166e+00  5.41336720e+00  7.08501597e-01 -1.36079872e+00\n",
      "  3.58278605e+00 -1.37130372e+00  5.56660722e-02  5.03372329e+00\n",
      "  5.49377185e+00  4.43201252e+00  7.98151293e+00  6.35555850e+00\n",
      "  3.88777358e+00  1.49430553e+00  6.73196192e-01  2.58618587e+00\n",
      "  5.03372329e+00  8.73195434e+00] \n",
      "\n",
      "alpha=1.0\n",
      "Train MSE: 3310.7245131795335\n",
      "Test MSE: 3965.0507925900956\n",
      "[ 3.64340453e+01 -3.46811771e+01  2.36026618e+02  2.09864957e+02\n",
      "  3.21848005e+00 -2.89558475e+01 -1.31984483e+02  9.79331424e+01\n",
      "  2.27530728e+02  7.98853517e+01  3.69619561e+00  5.01746366e+00\n",
      "  1.52418839e-01  4.33867569e+00 -1.31748567e+00 -3.31092688e+00\n",
      " -8.07774387e-01  5.38760702e-01  4.21267026e+00  4.00784331e+00\n",
      "  5.01746366e+00 -2.09421672e-01  4.04584596e+00  3.85573859e+00\n",
      "  1.35937459e+00 -9.93454347e-01  2.39498225e+00 -1.26615120e+00\n",
      "  2.17498693e+00  3.29728053e+00  1.52418839e-01  4.04584596e+00\n",
      "  1.11154178e+01  7.35768596e+00 -7.12360803e-01 -1.20341869e+00\n",
      " -3.48555885e-01  4.53207961e-01  1.38504847e+00  6.24968915e+00\n",
      "  4.33867569e+00  3.85573859e+00  7.35768596e+00  8.41268865e+00\n",
      "  1.61016969e+00 -6.44701305e-01  1.51839537e+00 -1.14467076e-01\n",
      "  4.23318270e+00  4.98488932e+00 -1.31748567e+00  1.35937459e+00\n",
      " -7.12360803e-01  1.61016969e+00 -1.15870684e+00 -2.40849745e+00\n",
      "  3.50315406e-01 -1.08391747e+00  5.64167226e-01  2.93560473e+00\n",
      " -3.31092688e+00 -9.93454347e-01 -1.20341869e+00 -6.44701305e-01\n",
      " -2.40849745e+00 -3.08689143e+00  1.13588704e+00 -2.30767785e+00\n",
      " -1.48355059e+00  9.24349996e-01 -8.07774387e-01  2.39498225e+00\n",
      " -3.48555885e-01  1.51839537e+00  3.50315406e-01  1.13588704e+00\n",
      " -3.55154511e+00  1.70092269e+00  2.67772764e+00  4.85757151e-01\n",
      "  5.38760702e-01 -1.26615120e+00  4.53207961e-01 -1.14467076e-01\n",
      " -1.08391747e+00 -2.30767785e+00  1.70092269e+00 -8.03835478e-01\n",
      " -8.37830375e-01  2.04596309e+00  4.21267026e+00  2.17498693e+00\n",
      "  1.38504847e+00  4.23318270e+00  5.64167226e-01 -1.48355059e+00\n",
      "  2.67772764e+00 -8.37830375e-01  4.55650547e-01  4.00031245e+00\n",
      "  4.00784331e+00  3.29728053e+00  6.24968915e+00  4.98488932e+00\n",
      "  2.93560473e+00  9.24349996e-01  4.85757151e-01  2.04596309e+00\n",
      "  4.00031245e+00  6.76239438e+00] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# альфа - это гиперпараметр, посмотрим как зависят значения весов от него\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "for a in np.arange(0, 1.1, 0.25):\n",
    "    if a == 0:\n",
    "        a += 0.00000001\n",
    "    ridge = Ridge(alpha=a)\n",
    "    ridge.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_tr = ridge.predict(X_train)\n",
    "    y_pred2 = ridge.predict(X_test)\n",
    "\n",
    "    print('alpha={}'.format(a))\n",
    "    print('Train MSE:', mean_squared_error(y_train, y_pred_tr))\n",
    "    print('Test MSE:', mean_squared_error(y_test, y_pred2))\n",
    "    print(ridge.coef_,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8951e14",
   "metadata": {},
   "source": [
    "А какой коэффициент альфа лучший ? И нужна ли здесь регуляризация ?\n",
    "\n",
    "Чтобы ответить на этот вопрос мы можем с помощью кросс-валидации перебрать различные значения альфы и выбрать лучшее значение. Этот процесс называется оптимизацией гиперпараметров. Альфа является гиперпараметром, потому что задача оптимизации функционала не позволяет найти ее оптимальное значение (в отличие от весов регрессии)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "597b134d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T14:59:06.864714Z",
     "start_time": "2021-09-19T14:59:06.727122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha value is 0.025125628240201005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "\n",
    "n_alphas = 200\n",
    "alphas = np.linspace(1e-10, 5, n_alphas)\n",
    "\n",
    "lasso_cv = LassoCV(alphas=alphas, cv=5, random_state=42)\n",
    "lasso_cv.fit(X, y)\n",
    "\n",
    "print(f'Optimal alpha value is {lasso_cv.alpha_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6da01131",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T14:59:18.317829Z",
     "start_time": "2021-09-19T14:59:13.094794Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.025125628240201005}\n"
     ]
    }
   ],
   "source": [
    "# Более общий способ использования кросс-валидации для поиска лучшего набора гиперпараметров\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'alpha':alphas}\n",
    "#print(params)\n",
    "cv = GridSearchCV(lasso,\n",
    "                  params,\n",
    "                  scoring='r2',\n",
    "                  cv=num_splits\n",
    "                 )\n",
    "cv.fit(X, y)\n",
    "\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "? GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48208331938183535"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a813f028",
   "metadata": {},
   "source": [
    "Больше про то, как задавать поле поиска и какие еще есть методы оптимизации гиперпараметров можете прочитать здесь\n",
    "\n",
    "https://scikit-learn.org/stable/modules/grid_search.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
